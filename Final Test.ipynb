{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e6bb82e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9dc8e0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Test.csv')\n",
    "# df = df.rename(columns={'Content': 'Text Content'})\n",
    "df = df.rename(columns={'Avg_rating': 'Avg rating'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cc4faa6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     !  ?\n",
       "0    0  1\n",
       "1    0  1\n",
       "2    0  1\n",
       "3    0  0\n",
       "4    0  2\n",
       "..  .. ..\n",
       "135  1  4\n",
       "136  2  0\n",
       "137  1  2\n",
       "138  0  1\n",
       "139  0  1\n",
       "\n",
       "[140 rows x 2 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from afinn import Afinn\n",
    "afinn = Afinn()\n",
    "\n",
    "def calculate_normalized_sentiment(text):\n",
    "    words = text.split()\n",
    "    if len(words) > 0:\n",
    "        return afinn.score(text) / len(words)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def calculate_lexical_diversity(text):\n",
    "    text = str(text)\n",
    "    \n",
    "    words = text.split()\n",
    "    \n",
    "    unique_words = set(words)\n",
    "    lexical_diversity = len(unique_words) / len(words) if len(words) > 0 else 0\n",
    "    \n",
    "    return lexical_diversity\n",
    "\n",
    "lexical_diversities = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    joke_text = row['Text Content']\n",
    "    \n",
    "    lexical_diversity = calculate_lexical_diversity(joke_text)\n",
    "    lexical_diversities.append({'Lexical Diversity': lexical_diversity})\n",
    "\n",
    "lexical_diversity_df = pd.DataFrame(lexical_diversities)\n",
    "\n",
    "\n",
    "\n",
    "def calculate_punctuation_frequency(text):\n",
    "    text = str(text)\n",
    "    \n",
    "    punctuation_marks = ['!', '?']\n",
    "    \n",
    "    punctuation_counts = {mark: text.count(mark) for mark in punctuation_marks}\n",
    "    \n",
    "    return punctuation_counts\n",
    "\n",
    "punctuation_frequencies = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "#     joke_id = row['joke_ids']\n",
    "    joke_text = row['Text Content']\n",
    "    \n",
    "    punctuation_frequency = calculate_punctuation_frequency(joke_text)\n",
    "#     punctuation_frequency['joke_id'] = joke_id\n",
    "    punctuation_frequencies.append(punctuation_frequency)\n",
    "\n",
    "punctuation_df = pd.DataFrame(punctuation_frequencies)\n",
    "\n",
    "punctuation_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d9ebbde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "df['Joke_len'] = df['Text Content'].str.len()\n",
    "df['sentiment_score'] = df['Text Content'].apply(calculate_normalized_sentiment)\n",
    "df = pd.concat([df, lexical_diversity_df], axis=1)\n",
    "df = pd.concat([df, punctuation_df], axis=1)\n",
    "df['Num_Words'] = df['Text Content'].apply(lambda x: len([word for word in word_tokenize(x) if word.isalpha()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "08251eaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text Content</th>\n",
       "      <th>Avg_Rating</th>\n",
       "      <th>Joke_len</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>Lexical Diversity</th>\n",
       "      <th>!</th>\n",
       "      <th>?</th>\n",
       "      <th>Num_Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Q.\\tWhat's O. J. Simpson's Internet address?  ...</td>\n",
       "      <td>-2.034618</td>\n",
       "      <td>94</td>\n",
       "      <td>-0.642857</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>How many feminists does it take to screw in a ...</td>\n",
       "      <td>-1.943754</td>\n",
       "      <td>75</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>Q. Did you hear about the dyslexic devil worsh...</td>\n",
       "      <td>-0.704781</td>\n",
       "      <td>83</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>They asked the Japanese visitor if they have e...</td>\n",
       "      <td>-0.671219</td>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>Q:  What did the blind person say when given s...</td>\n",
       "      <td>-1.436065</td>\n",
       "      <td>87</td>\n",
       "      <td>-0.294118</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>145</td>\n",
       "      <td>America: 8:00 - Welcome to work! 12:00 - Lunch...</td>\n",
       "      <td>0.205030</td>\n",
       "      <td>311</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>146</td>\n",
       "      <td>It was the day of the big sale. Rumors of the ...</td>\n",
       "      <td>1.782516</td>\n",
       "      <td>592</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>147</td>\n",
       "      <td>Recently a teacher, a garbage collector, and a...</td>\n",
       "      <td>2.968233</td>\n",
       "      <td>795</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>0.711268</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>148</td>\n",
       "      <td>A little girl asked her father, \"Daddy? Do all...</td>\n",
       "      <td>2.394606</td>\n",
       "      <td>185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>149</td>\n",
       "      <td>In an interview with David Letterman, Carter p...</td>\n",
       "      <td>2.770453</td>\n",
       "      <td>879</td>\n",
       "      <td>0.155844</td>\n",
       "      <td>0.655844</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                       Text Content  \\\n",
       "0             4  Q.\\tWhat's O. J. Simpson's Internet address?  ...   \n",
       "1             6  How many feminists does it take to screw in a ...   \n",
       "2             7  Q. Did you hear about the dyslexic devil worsh...   \n",
       "3            12  They asked the Japanese visitor if they have e...   \n",
       "4            14  Q:  What did the blind person say when given s...   \n",
       "..          ...                                                ...   \n",
       "135         145  America: 8:00 - Welcome to work! 12:00 - Lunch...   \n",
       "136         146  It was the day of the big sale. Rumors of the ...   \n",
       "137         147  Recently a teacher, a garbage collector, and a...   \n",
       "138         148  A little girl asked her father, \"Daddy? Do all...   \n",
       "139         149  In an interview with David Letterman, Carter p...   \n",
       "\n",
       "     Avg_Rating  Joke_len  sentiment_score  Lexical Diversity  !  ?  Num_Words  \n",
       "0     -2.034618        94        -0.642857           0.857143  0  1         12  \n",
       "1     -1.943754        75         0.266667           1.000000  0  1         15  \n",
       "2     -0.704781        83         0.000000           1.000000  0  1         16  \n",
       "3     -0.671219       100         0.000000           1.000000  0  0         16  \n",
       "4     -1.436065        87        -0.294118           0.941176  0  2         17  \n",
       "..          ...       ...              ...                ... .. ..        ...  \n",
       "135    0.205030       311         0.047619           0.571429  1  4         43  \n",
       "136    1.782516       592         0.032787           0.672131  2  0        121  \n",
       "137    2.968233       795         0.007042           0.711268  1  2        136  \n",
       "138    2.394606       185         0.000000           0.857143  0  1         33  \n",
       "139    2.770453       879         0.155844           0.655844  0  1        152  \n",
       "\n",
       "[140 rows x 9 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "4633ba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# with open('linear_regression_model.pkl', 'rb') as file:\n",
    "#     loaded_model = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "329b067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "X = df.iloc[:, 3:]\n",
    "y_test = df.iloc[:, 2]\n",
    "\n",
    "# y_pred = loaded_model.predict(X)\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# r_squared = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e0ca2f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "de7b315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('ensemble_model.pkl', 'rb') as model_file:\n",
    "    (bagged_linear_reg, bagged_svm_linear, bagged_ridge_reg, bagged_lasso_reg) = pickle.load(model_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4791437c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1.6037377451373767\n",
      "R-squared: 0.2016590102708573\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "with open('ensemble_model.pkl', 'rb') as model_file:\n",
    "    ensemble_models = pickle.load(model_file)\n",
    "\n",
    "bagged_linear_reg, bagged_svm_linear, bagged_ridge_reg, bagged_lasso_reg = ensemble_models\n",
    "\n",
    "X_test = X  # Replace with your test data\n",
    "\n",
    "y_pred_linear_reg = bagged_linear_reg.predict(X_test)\n",
    "y_pred_svm_linear = bagged_svm_linear.predict(X_test)\n",
    "# y_pred_ridge_reg = bagged_ridge_reg.predict(X_test)\n",
    "# y_pred_lasso_reg = bagged_lasso_reg.predict(X_test)\n",
    "\n",
    "ensemble_predictions = (y_pred_linear_reg + y_pred_svm_linear) / 2\n",
    "\n",
    "mse = mean_squared_error(y_test, ensemble_predictions)\n",
    "r_squared = r2_score(y_test, ensemble_predictions)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"R-squared:\", r_squared)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "75f3c971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Joke_len</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>Lexical Diversity</th>\n",
       "      <th>!</th>\n",
       "      <th>?</th>\n",
       "      <th>Num_Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94</td>\n",
       "      <td>-0.642857</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87</td>\n",
       "      <td>-0.294118</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>311</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>592</td>\n",
       "      <td>0.032787</td>\n",
       "      <td>0.672131</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>795</td>\n",
       "      <td>0.007042</td>\n",
       "      <td>0.711268</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>879</td>\n",
       "      <td>0.155844</td>\n",
       "      <td>0.655844</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Joke_len  sentiment_score  Lexical Diversity  !  ?  Num_Words\n",
       "0          94        -0.642857           0.857143  0  1         12\n",
       "1          75         0.266667           1.000000  0  1         15\n",
       "2          83         0.000000           1.000000  0  1         16\n",
       "3         100         0.000000           1.000000  0  0         16\n",
       "4          87        -0.294118           0.941176  0  2         17\n",
       "..        ...              ...                ... .. ..        ...\n",
       "135       311         0.047619           0.571429  1  4         43\n",
       "136       592         0.032787           0.672131  2  0        121\n",
       "137       795         0.007042           0.711268  1  2        136\n",
       "138       185         0.000000           0.857143  0  1         33\n",
       "139       879         0.155844           0.655844  0  1        152\n",
       "\n",
       "[140 rows x 6 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3068c030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
